# **Compliance Radar â€” Organizational Risk & Integrity Analysis**

*Corporate Compliance & Operational Risk Detection*

---

## **1. Project Overview**

This project analyzes the `org_compliance_data.db` dataset â€” a comprehensive organizational data source containing department-level operational metrics, reporting patterns, financial indicators, audit results, and anonymized engagement scores.
The objective is to design a **data-driven analytical framework** capable of identifying potential non-compliance signals, uncovering key explanatory factors, and generating actionable recommendations to strengthen corporate integrity.

The analysis integrates:

* Statistical reasoning
* Predictive modeling
* Ethical and interpretability insights
* Evidence-based governance recommendations

---

## **2. Problem Definition**

After examining the structure of the data, this project frames the main task as a **binary classification problem**:

> **Goal:** Predict whether a department is *high-risk* (`is_high_risk = 1`) or *not high-risk* (`is_high_risk = 0`) based on operational, managerial, engagement, and compliance metrics.

The `high_risk_departments` table is used to create the binary label.
Additional exploratory components (e.g., clustering for pattern discovery) may also be included to complement the supervised task.

---

## **3. Dataset Description**

The database contains four tables:

### **3.1 departments (709 rows, 37 columns)**

The core dataset with features describing:

* Department structure, size, type
* Manager/supervisor experience
* Training, reporting, and audit metrics
* Operational health and risk exposure indicators

### **3.2 high_risk_departments (201 rows, 37 columns)**

Subset of departments flagged as high-risk.
Used to create the binary target variable.

### **3.3 risk_summary_by_division (2 rows, 8 columns)**

Aggregated insights per division (Corporate HQ vs Regional Operations).

### **3.4 data_dictionary (39 rows, 4 columns)**

Provides definitions and data types for all fields.

---

## **4. Data Cleaning & Integrity Resolution**

A key data issue identified early was **duplicate department IDs** in `departments` with differing values.
Rather than removing any rows â€” which would distort the dataset and break alignment with the high-risk table â€” we **preserved all rows** and added a flag to track identifier conflicts.

**Final decision:**
All department records were kept; no row deletions performed.
A new feature (`id_conflict_flag`) indicates whether a `dept_id` appears multiple times with inconsistent attributes.

This preserves data fidelity while enabling the model to learn from potential instability signals.

---

## **5. Feature Engineering**

Key feature additions include:

* **Binary target:** `is_high_risk` (from high_risk_departments)
* **Duplicate-ID indicator:** `id_conflict` flag
* Possible derived features (to be completed during EDA):

  * Reporting gap ratios
  * Audit score changes (Q1 â†’ Q2)
  * Normalized violations
  * Interaction/engagement composite metrics

---

## **6. Exploratory Data Analysis (EDA)**

The EDA section includes:

* Distribution plots of numerical variables
* Missingness heatmaps and patterns
* Correlation matrices and risk-factor clustering
* Group-based comparisons (divisions, categories, types)
* Visual contrasts between high-risk vs low-risk departments

*Figures will be inserted here:*

```
ðŸ“Œ Placeholder for EDA images  
(e.g., histograms, boxplots, heatmaps, risk score distributions)
```

---

## **7. Problem Modeling Approach**

### **Model Type:**

**Binary classification**

### **Models Tested:**

1. **Logistic Regression** (interpretable baseline)
2. **Random Forest Classifier**
3. **XGBoost / Gradient Boosting Classifier**

Each model is evaluated first using default hyperparameters on a **validation split**, then fully optimized using **cross-validation**.

---

## **8. Preprocessing Pipeline**

Steps include:

* Missing value imputation
* Outlier detection and treatment
* One-hot encoding of categorical variables
* Scaling of numerical features where appropriate
* Train/validation/test splitting
* Feature importance & SHAP interpretability steps

---

## **9. Hyperparameter Tuning**

Cross-validation is performed (GridSearchCV or RandomizedSearchCV).
For each model, the following hyperparameters are tuned:

Examples:

* **Logistic Regression:** C, penalty, solver
* **Random Forest:** n_estimators, max_depth, min_samples_split, min_samples_leaf
* **XGBoost:** learning_rate, max_depth, subsample, colsample_bytree, n_estimators

*Full hyperparameter tables will be added after experimentation.*

---

## **10. Evaluation Metrics**

Primary metrics:

* **F1-score**
* **Precision, Recall** (especially important for identifying high-risk departments)
* **ROC-AUC**
* **Confusion matrix**

---

## **11. Results & Model Comparison**

```
ðŸ“Œ Placeholder for performance table  
ðŸ“Œ Placeholder for ROC curves  
ðŸ“Œ Placeholder for confusion matrix figures  
```

---

## **12. Insights & Interpretation**

This section will include:

* SHAP value analysis
* Feature importance rankings
* Interpretation of key variables driving risk
* Potential causal or governance explanations

---

## **13. Ethical Considerations**

Topics addressed:

* Risk of unfairly labeling departments without context
* Interpretability requirements for governance decisions
* Avoiding automation bias (model outputs must not replace compliance audit judgment)
* Transparency in how features influence predictions

---

## **14. Recommendations & Actionable Findings**

* Which operational metrics most strongly predict risk
* Early-warning indicators
* Governance improvements
* Training or reporting processes that reduce violations

---

## **15. Repository Structure**

Compliance-Radar-ML/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ main.ipynb
â”‚
â”œâ”€â”€ reports/
â”‚
â”œâ”€â”€ images/
â”‚
â””â”€â”€ README.md


---

## **16. Contributors**

Student 1: 
Student 2:
Student 3:
Student 4:

Bachelorâ€™s in Artificial Intelligence & Management
Luiss Guido Carli University